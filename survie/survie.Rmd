---
title: "UER Modélisation"
subtitle: "Survie"
author: "Thomas Ferté"
date: "26/02/2022"
output:
  beamer_presentation:
    theme: "Berlin"
    colortheme: "dolphin"
    slide_level: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
set.seed(1)
# devtools::install_github("AckerDWM/gg3D")
library(dplyr)
library(ggplot2)
library(gg3D)
library(survival)
library(survminer)
```

# Rappels

## Ecrivez le modèle correspondant

```{r simustartsimple, fig.height=5}
n = 10^3
dfstartsimple <- data.frame(age = runif(n = n, min = 20, max = 90),
                            sexe = rbinom(n = n, size = 1, prob = 0.5)) %>%
  mutate(VO2max = 35 + 5*sexe - age/10 + rnorm(n = n, sd = 3),
         sexe = factor(sexe, levels = c(0, 1), labels = c("femme", "homme")))

ggplot(dfstartsimple, mapping = aes(x = age, y = VO2max, color = sexe)) +
  geom_point()
```

## Solution

$$VO2max_i = \beta_0 + \beta_1 age_i + \beta2 sexe_i + \epsilon_i$$

$\epsilon_i \sim \mathcal{N}(0, \sigma_e^2)$

## Ecrivez le modèle correspondant

```{r simustartsimplereglog, fig.height=5}
expit <- function(x) exp(x)/(1+exp(x))
logit <- function(x) log(x/(1-x))

dfintuition <- data.frame(age = runif(n = n, min = 20, max = 90),
                          sexe = rbinom(n = n, size = 1, prob = 0.5)) %>%
  mutate(proba_demence = expit(-6 + age/10 + sexe * 2),
         demence = rbinom(n = n, size = 1, prob = proba_demence),
         sexe = factor(sexe, levels = c(0, 1), labels = c("femme", "homme")))

dfintuition %>%
  mutate(age_quali = cut(age, breaks = c(2:9)*10)) %>%
  group_by(age_quali, sexe) %>%
  summarise(prop_demence = sum(demence)/n(),
            n = n()) %>%
  ggplot(mapping = aes(x = age_quali, y = prop_demence, color = sexe, size = n)) +
  geom_point() +
  labs(y = "Proportion of dementia", x= "Age category", size = "Nb patient")

```


## Solution

$$Logit(P(Dementia_i = 1)) = \beta_0 + \beta_1 age_i + \beta2 sexe_i$$

# Intuition

## Diagnostique et décès

\tiny

On s'intéresse au lien entre le diagnostic d'un cancer et le décès d'un patient pour cela on recueil les données de plusieurs patients :

```{r fig.height=4}
n_survintuition = 5
dfsurvIntuition <- data.frame(xstart = runif(0, 10, n = n_survintuition),
                              duration = runif(0, 10, n = n_survintuition)) %>%
  mutate(xend = xstart + duration,
         event = 1) %>%
  tibble::rowid_to_column(var = "patient")

ggplot(dfsurvIntuition, mapping = aes(x = xstart,
                                      xend = xend,
                                      y = patient,
                                      yend = patient)) +
  geom_segment() +
  geom_point(mapping = aes(x = xend, color = "death")) +
  geom_point(mapping = aes(x = xstart, color = "diagnosis")) +
  labs(x = "Durée de suivi (mois)")

```

## Représentation en temps depuis diagnostic

```{r fig.height=4}
plotsimplsurv <- ggplot(dfsurvIntuition, mapping = aes(x = 0,
                                                       xend = duration,
                                                       y = patient,
                                                       yend = patient)) +
  geom_segment() +
  geom_point(mapping = aes(x = duration, color = "death")) +
  geom_point(mapping = aes(x = 0, color = "diagnosis")) +
  labs(x = "Durée de suivi depuis diagnostic (mois)") +
  theme(legend.position = "bottom")

plotsimplsurv
```

## Représentation Kaplan Meier

\footnotesize

```{r fig.height=5}

fitSurvival <- survfit(formula = Surv(time = duration, event = event) ~ 1, data = dfsurvIntuition)
p1 <- ggsurvplot(fitSurvival, conf.int = FALSE, palette = "black", legend = "none")

ggpubr::ggarrange(p1$plot, plotsimplsurv, nrow = 2)
```

Chaque marche correspond à événement et à une diminution de 20% de la probabilité de survie.

## Définitions

- *Date des dernières nouvelles* : date la plus récente où l'on a pu recueillir des informations sur un sujet.
- *Temps de participation = temps de suivi* : délai entre date d'entrée dans l'étude et la date de dernières nouvelles.
- *Date de point* : date au delà de laquelle on ne tiendra pas compte des informations sur le sujet.
- *Recul pour une étude* = date de point - date de début de l'étude
- *Recul pour un sujet* = date de point - date d'entrée dans l'étude

# Mesurer la survie

## fonction de densité

Probabilité de faire l'événement à un instant $t$

$$f(t) = \lim_{\Delta t \to 0+} \frac{P(t \leq T < t + \Delta t)}{\Delta t}$$

## fonction de répartition

Probabilité de faire l'événement avant $t$. Correspond au cumul de $f(t)$ de $0$ à $t$

$$
\begin{aligned}
F(t) & = P(T \leq t) \\
& = \int_{0}^t f(u)du \\
\end{aligned}
$$

Expliquez pourquoi $F(0) = 0$ et $\lim_{t \to +\infty} F(t) = 1$

## fonction de survie

La fonction de survie correspond à la probabilité de ne pas avoir encore fait l'événement à l'instant $t$

$$S(t) = P(T>t) = 1 - F(t)$$

## fonction de risque

\footnotesize	

Elle correspond à la probabilité de faire l'événement à l'instant $t$ sachant que le patient est toujours indemne juste avant cet instant. On parle de fonction de risque instantané.

$$
\begin{aligned}
\alpha(t) & = \lim_{\Delta t \to 0+}  \frac{P(t \leq T < t+\Delta t|T \geq t)}{\Delta t} \\
& = \lim_{\Delta t \to 0+}  \frac{P(T \geq t | t \leq T < t+\Delta t)P(t \leq T < t+\Delta t)}{\Delta t \times P(T \geq t)} \leftarrow	\text{ Bayes theorem} \\
& = \lim_{\Delta t \to 0+}  \frac{1 \times P(t \leq T < t+\Delta t)}{\Delta t \times P(T \geq t)} \\
& = \lim_{\Delta t \to 0+}  \frac{P(t \leq T < t+\Delta t)}{\Delta t}  \times \frac{1}{P(T \geq t)} \\
& = \frac{f(t)}{S(t)}
\end{aligned}
$$

Bayes theorem : $P(A|B) = \frac{P(B|A)P(A)}{P(B)}$

## fonction de risque (2)

\footnotesize	

$S(t) = 1 - F(t) = 1 - \int_0^t f(u)du$

En dérivant on obtient : $\frac{dS(t)}{dt} = 0 - f(t) = -f(t)$

Par ailleurs

$$
\begin{aligned}
\alpha(t) &= \frac{f(t)}{S(t)} \\
& = - \frac{dS(t)}{dt} \times \frac{1}{S(t)} \\
& = - \frac{d}{dt}log(S(t))
\end{aligned}
$$

NB: $\frac{d}{dx}log(f(x)) = \frac{1}{f(x)} \times \frac{d}{dx}f(x)$

## fonction de risque (3)

On a $\alpha(t) = - \frac{d}{dt}log(S(t))$ si on poursuit :

$$
\begin{aligned}
\alpha(t) &= - \frac{d}{dt}log(S(t)) \\
\int_0^t\alpha(u)du &= - log(S(t)) \\
- \int_0^t\alpha(u)du &= log(S(t)) \\
exp(- \int_0^t\alpha(u)du) &= exp(log(S(t))) \\
exp(- \int_0^t\alpha(u)du) &= S(t) \\
\end{aligned}
$$

## fonction de risque cumulé

Elle correspond au cumul de la fonction précédente :

$$A(t) =  \int_0^t \alpha(u)du$$

## Exercice

Soit un risque instantané constant $\alpha(t) = \lambda$

Trouvez la fonction de densité, la fonction de répartition, la fonction de survie, la fonction de risque cumulée.

Aide :

$f(t) = S(t) \times \alpha(t)$

$F(t) = 1 - S(t)$

$S(t) = exp(-\int_0^t \alpha(u) du)$

$A(t) = \int_0^t \alpha(u) du$

## Exercice - Solution

\tiny

$S(t) = exp(-\int_0^t \alpha(u) du) = exp(-\int_0^t \lambda) = exp(-\lambda t)$

$A(t) = \int_0^t \alpha(u) du = \int_0^t \lambda du = \lambda t$

$F(t) = 1 - S(t) = 1 - exp(-\lambda t)$

$f(t) = S(t) \times \alpha(t) = exp(-\lambda t) \times \lambda$

```{r fig.height=4}
dfExpsurvival <- data.frame(time = seq(0,100, by = 0.1),
                            alphat = 0.01) %>%
  mutate(instant_risk = time^0*alphat,
         survival_risk = exp(-alphat*time),
         cumulated_instant_risk = -log(survival_risk),
         repartition = 1 - survival_risk,
         density = survival_risk*instant_risk) %>%
  tidyr::pivot_longer(cols = instant_risk:density)

ggplot(dfExpsurvival, mapping = aes(x = time, y = value)) +
  geom_line() +
  facet_wrap(name ~ ., scales = "free_y") +
  theme(legend.position = "bottom")
```

# Censure et troncature

## Censure

Lorsque l'on ne connait pas la date précise de l'événement :

- censure à droite : l'événement survient après la fin du suivi
- censure à gauche : l'événement survient avant le début du suivi
- censure par intervalle : l'événement survient entre deux temps de suivi

## Censure en image

```{r fig.height=4}
dfcensure <- data.frame(patient = c(rep("censure à gauche", 2),
                                    rep("censure à droite", 2),
                                    rep("censure par intervalle", 3)),
                        time_start = c(0, 2,
                                       0, 8,
                                       0, 4, 7),
                        time_end = c(2, 10,
                                     8, 10,
                                     4, 7, 10),
                        suivi = c("not observed", "observed",
                                  "observed", "not observed",
                                  "observed", "not observed", "observed")) %>%
  mutate(suivi = as.factor(suivi),
         suivi = forcats::fct_rev(suivi))

dfeventcensure <- data.frame(patient = c("censure à gauche",
                                         "censure à droite", 
                                         "censure par intervalle"),
                             time_start = c(1, 9, 5.5))

ggplot(dfcensure,
       mapping = aes(x = time_start,
                     y = patient,
                     xend = time_end,
                     yend = patient,
                     lty = suivi)) +
  geom_segment() +
  geom_point(dfeventcensure,
             mapping = aes(x = time_start, y = patient,
                           shape = "event"),
             inherit.aes = FALSE,
             size = 4) +
  scale_shape_manual(values = 4) +
  theme(legend.position = "bottom") +
  labs(x = "Time", y = "", shape = "", linetype = "")

```

## Troncature

Une observation est dite tronquée si elle est conditionnelle à un autre évènement.

- Troncature à gauche : les patients de la base paquid sont recrutés parmi ceux les personnes ayant plus de 65 ans (troncature des patients de moins de 65 ans).
- Troncature à droite : très rare
- Troncature par intervalle : lorsque l'on utilise un registre, les patients ayant fait l'événement étudié par le registre avant sa mise en place ne sont pas pris en compte. Les patients répertoriés après la consultation du registre ne seront pas non plus pris en compte.

Contrairement à la censure, les patients ayant eu une troncature ne sont pas renseignés dans la base de données.

# Vraisemblance

## Vraisemblance - rappel

La vraisemblance correspond à la “probabilité” d’observer l’échantillon selon le modèle.

$\mathcal{L} = \prod_{i=1}^n \mathcal{L}_i$

Pour les individus $i$ d'un échantillon de taille $n$

## Vraisemblance - pas de censure

$\mathcal{L}_i = f(\tilde{T_i})$

avec $\tilde{T_i}$ le délai avant évenement de l'individu $i$ et $f$ la fonction de densité de probabilité

## Vraisemblance - censure à droite

$\mathcal{L}_i = f(\tilde{T_i})^{\delta_i}S(\tilde{T_i})^{1-\delta_i}$

avec $\tilde{T_i}$ le délai avant évenement ou censure de l'individu $i$ et $S$ la fonction de survie.

## Exercice

\tiny

On fait l'hypothèse que la survie de patients suit une loi exponentielle de paramètre $\lambda$ avec :

$S(t) = exp(-\lambda t)$

$f(t) = \lambda exp(-\lambda t)$

```{r}
dfExVraisemblance <- data.frame(patient = c(1,2,3),
                                time = c(10, 20, 40),
                                event = c(1, 0, 1))

dfExVraisemblance %>% knitr::kable(booktabs = TRUE)
```


Parmi ces deux propositions, quelle valeur de $\lambda$ vous paraît la plus probable ?

- 0.05
- 0.5

NB : $\mathcal{L}_i = f(\tilde{T_i})^{\delta_i}S(\tilde{T_i})^{1-\delta_i}$

## Solution

\tiny

```{r fig.height=4, echo = TRUE}
lambda = seq(0.001, 0.6, by = 0.003)
vec_vraisemblance <- sapply(lambda, function(lambda_j){
  f_ti <- lambda_j * exp(- lambda_j * dfExVraisemblance$time)
  s_ti <- exp(- lambda_j * dfExVraisemblance$time)
  vraisemblance <- prod(f_ti^dfExVraisemblance$event*s_ti^(1-dfExVraisemblance$event))
})
plot(lambda, vec_vraisemblance, ylab = "Vraisemblance", type = 'l')
```

Réponse : 0.05

## Vraisemblance - censure à droite et troncature à gauche

$\mathcal{L}_i = \frac{f(\tilde{T_i})^{\delta_i}S(\tilde{T_i})^{1-\delta_i}}{S(T_{0i})}$

avec $\tilde{T_i}$ le délai avant évenement ou censure de l'individu $i$ et $T_{0i}$ le délai avant troncature.

Dans la suite du cours, on ne s'intéressera qu'au cas avec censure à droite et troncature à gauche.

# Kaplan Meier

## Définition

\tiny

- $d_j$ : nombre de sujets subissant l'événement au temps $t_j$
- $n_j$ : nombre de sujets à risque au temps $t_j$
- $\widehat{S}(t) = \prod_{j:t_j<t} \frac{n_j - d_j}{n_j}$
- D'où : $\widehat{S}(t_{j+1}) = \widehat{S}(t_{j}) \times \frac{n_{j+1} - d_{j+1}}{n_{j+1}}$

## En pratique (1)

\tiny

```{r fig.height=3, echo=FALSE}
dfKm <- data.frame(subject = c(1, 2, 3, 4, 5),
                   time = c(10, 15, 20, 22, 30),
                   event = c(1, 0, 1, 0, 0))

dfKm %>% knitr::kable(booktabs = TRUE)
```

## En pratique (2)

\tiny

```{r}
dfKm %>% knitr::kable(booktabs = TRUE)
```

```{r}
dfKmAnalysedStep1 <- data.frame(time = c(0, 10, 15, 20, 22, 30),
                                n_j = c(5, 5, 4, 3, 2, 1),
                                d_j = c(0, 1, 0, 1, 0, 0))
dfKmAnalysedStep1 %>% knitr::kable(booktabs = TRUE)
```

## En pratique (3)

\tiny

```{r echo=TRUE}
dfKmAnalysedStep2 <- dfKmAnalysedStep1 %>%
  mutate(Prob_cond = (n_j - d_j)/n_j,
         survival = cumprod(Prob_cond))
dfKmAnalysedStep2 %>% knitr::kable(booktabs = TRUE)
```

## En pratique (4)

\tiny

```{r fig.height=3, echo=FALSE}
dfKmAnalysedStep2 %>% knitr::kable(booktabs = TRUE)

ggplot(dfKmAnalysedStep2, mapping = aes(x = time, y = survival)) +
  geom_step() +
  lims(y = c(0, 1))

```

## Exercice

\tiny

Construisez l'estimateur de KM :

```{r}
dfKmExo <- data.frame(subject = c(1, 2, 3, 4, 5),
                      time = c(2, 8, 10, 14, 16),
                      event = c(0, 1, 1, 0, 1))

dfKmExoCalc <- data.frame(time = c(0, 8, 10, 16),
                          n_j = c(5, 4, 3, 1),
                          d_j = c(0, 1, 1, 1)) %>%
  mutate(Prob_cond = (n_j - d_j)/n_j,
         survival = cumprod(Prob_cond))

pKmExo <- ggplot(dfKmExoCalc, mapping = aes(x = time, y = survival)) +
  geom_step() +
  lims(y = c(0, 1))

knitr::kable(dfKmExo, booktabs = TRUE)
```

## Solution

\tiny

```{r}
knitr::kable(dfKmExo, booktabs = TRUE)

knitr::kable(dfKmExoCalc, booktabs = TRUE)

```

## Intervalles de confiance

Formule de Greenwood

Formule de Rothman (++)

# Log-rank

## Intuition

\small

Objectif : comparer deux (ou plus) courbes de survie

Sous H0 (pas de différence), le nombre attendu d'événement à un instant $j$ dans chacun des groupes est similaire au nombre d'événement dans l'échantillon pondéré par le nombre d'individu dans chaque groupe.

On va comparer ce nombre attendu au nombre observé. Si la différence est trop grande alors on conclut à une différence significative.

Suit une loi du Chi-2 à $g-1$ où $g$ est le nombre de groupe (e.g $ddl = 1$ si 2 groupes)

## En pratique (1)

```{r}
dfLogRankdata <- data.frame(patient = 1:10,
                            sexe = c("M", "M", "M", "F", "M", "M", "F", "F", "F", "F"),
                            time = c(4, 6, 8, 11, 15, 15, 20, 20, 25, 31),
                            died = c(1, 1, 0, 1, 1, 1, 1, 0, 1, 0))

modelKmLogrank <- survfit(Surv(time = time, event = died) ~ sexe, data = dfLogRankdata)

plotKmLogRank <- ggsurvplot(modelKmLogrank)

dfLogRank <- data.frame(time = c(4, 6, 11, 15, 20, 25),
                        Male_at_risk = c(5, 4, 2, 2, 0, 0),
                        Female_at_risk = c(5, 5, 5, 4, 4, 2),
                        Male_deaths = c(1, 1, 0, 2, 0, 0),
                        Female_deaths = c(0, 0, 1, 0, 1, 1)) %>%
  mutate(Deaths = Male_deaths + Female_deaths,
         Exp_deaths_male = Deaths*(Male_at_risk/(Female_at_risk + Male_at_risk)),
         Exp_deaths_female = Deaths*(Female_at_risk/(Female_at_risk + Male_at_risk)))

stat_male <- (sum(dfLogRank$Male_deaths) - sum(dfLogRank$Exp_deaths_male))^2/sum(dfLogRank$Exp_deaths_male)
stat_female <- (sum(dfLogRank$Female_deaths) - sum(dfLogRank$Exp_deaths_female))^2/sum(dfLogRank$Exp_deaths_female)

stat_total <- stat_female + stat_male
```

::: columns

:::: column
```{r}
dfLogRankdata %>% knitr::kable(booktabs = TRUE)
```
::::

:::: column
```{r fig.height=5}
plotKmLogRank
```
::::

:::

## En pratique (2)

\tiny

```{r}
dfLogRank %>% select(-Exp_deaths_female, -Exp_deaths_male) %>% knitr::kable(booktabs = TRUE)
```

## En pratique (3)

\tiny

$$Expected\_death\_male = Deaths \times \frac{Male\_at\_risk}{Male\_at\_risk + Female\_at\_risk}$$

```{r}
dfLogRank %>% knitr::kable(booktabs = TRUE)
```

## En pratique (4)

\tiny

```{r}
dfLogRank %>% knitr::kable(booktabs = TRUE)
```


$$\mathcal{X}^2 = \sum_{group} \Big(\frac{(\sum observed - \sum expected)^2}{\sum expected} \Big)$$

$$
\begin{aligned}
\mathcal{X}^2 &= \sum_{group} \Big(\frac{(\sum observed - \sum expected)^2}{\sum expected} \Big) \\
  &= \frac{(4-1.897)^2}{1.897} + \frac{(3-5.103)^2}{5.103} \\
  &= 3.199
\end{aligned}
$$

# Cox

## Un modèle de régression

Modèle à risque proportionnel

$\alpha(t, Z) = \alpha_0(t) exp(\beta_1 X_{i1} + \beta_2 X_{i2} + ... + \beta_p X_{ip})$

A noter l'absence de $\beta_0$ "remplacé" par $\alpha_0(t)$

## Exercice

$\alpha(t, Z) = \alpha_0(t) exp(\beta_1 X_{i1} + \beta_2 X_{i2} + ... + \beta_p X_{ip}$

Soit un modèle univarié évaluant le risque de décès en fonction du bras de traitement (0: placebo, 1: traitement).

Ecrivez le risque instantané de faire l'événement chez un patient prenant un placebo, idem chez un patient prenant le traitement.

Déduisez en le risque relatif instantané de décéder chez les patient prenant le traitement par rapport à ceux prenant le placebo.

## Solution

Modèle : $\alpha(t, Z) = \alpha_0(t) exp(\beta_1 Traitement_{i1})$

Patient $j$ dans le groupe placebo : $\alpha(t, Z_j) = \alpha_0(t) exp(0) = \alpha_0(t)$

Patient $k$ dans le groupe traitement : $\alpha(t, Z_k) = \alpha_0(t) exp(\beta_1)$

Rapport de risque : $HR = RR = \frac{\alpha_0(t) exp(\beta_1)}{\alpha_0(t)} = e^{\beta_1}$

## Spécification du modèle

- Choix des variables : idem régression linéaire et logistique

- Variables catégorielles : idem régression linéaire et logistique

- Modification d'effet : idem régression linéaire et logistique

## Vraisemblance partielle

\tiny

Soit $t_1, ..., t_k$ les temps d'événements (décès) en considérant qu'il n'y a qu'un seul événement à chaque temps.

Chaque individu $i$ a un risque instantané de faire l'événement qui dépend du temps et de ses covariables $\alpha_i(t_i, Z_i)$.

On peut écrire la vraisemblance telle que :

$$
\begin{aligned}
  L_i(\beta) &= P(\text{individu j fait l'évenement}|\text{un des individus a fait l'événement}) \\
  &=  \frac{P(\text{individu j fait l'évenement}|\text{à risque à l'instant } t_j)}{\sum P(\text{individus fassent l'événement}|\text{à risque à l'instant } t_j)}\\
  &= \frac{\alpha_0(t_j)exp(\beta_1 X_j)}{\sum \alpha_0(t_j)exp(\beta_1 X_l)} \\
  &= \frac{\alpha_0(t_j)exp(\beta_1 X_j)}{\alpha_0(t_j) \sum exp(\beta_1 X_l)} \\
  &= \frac{exp(\beta_1 X_j)}{\sum exp(\beta_1 X_l)}
\end{aligned}
$$

Donc pas besoin d'estimer $\alpha_0(t)$ !!!

## Intervalle de confiance

$IC : exp([\widehat \beta_j \pm z_{\alpha/2} \sqrt{\widehat{var}(\widehat\beta_j)}])$

## Tests statistiques

- Test global : Rapport de vraisemblance (+++), Wald, Score
- Apport d'une variable : Wald (+++), Rapport de vraisemblance, Score
- Apport d'un ensemble de variables : Rapport de vraisemblance (+++), Wald, Score

## Tests statistiques - Wald (un seul paramètre)

Soit $\widehat\beta_1$ l'estmateur du coefficient $\beta_1$ par le modèle et $SE_{\widehat\beta_1}$ sont erreur standard associée alors la statistique de test de wald est définie comme :

$Wald = \frac{\widehat\beta_1}{SE_{\widehat\beta_1}}$

et suit une loi du Chi-2 à 1 ddl.

## Tests statistiques - Log-vraisemblance (comparaison de modèle)

Soit $m2$ le modèle complet et $m1$ le modèle restreint, le rapport de vraisemblance est défini comme :

$RV = 2\times (loglik(m2)-loglik(m1))$

Dans ce cas $RV$ suit une loi du Ch-2 avec un ddl égal à la différence du nombre de paramètres ($\beta$) entre les deux modèles.

## Tests statistiques - Score (un seul paramètre)

Soit $\beta$ le paramètre du modèle de cox à tester. Soit $U(\beta)$ la dérivée première de la vraisemblance du modèle selon ce paramètre et $I(\beta)$ l'opposée de l'espérance de la dérivée seconde de la vraisemblance de ce paramètre. Alors la statistique du score est définie telle que :

$Score = \frac{U(\beta)^2}{I(\beta)}$

et suit une loi du Chi-2 à 1 ddl

## Hypothèses du modèle

<!-- - Proportional Hazards assumption : test résidus de Schoenfeld -->

<!-- - Linéarity : polynômes fractionnaires -->

<!-- ## Résidus de Schoenfeld -->

<!-- ## Polynômes fractionnaires -->

<!-- Test plusieurs transformations des variables quantitatives. -->

<!-- Cf package `mfp` -->

## Introduire le temps dans un modèle de survie

## Fin

Questions ?